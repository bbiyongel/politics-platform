{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.2101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('sentiment_data_v1.csv')\n",
    "temp = [len(str(ele)) for ele in data.text.tolist()] \n",
    "res = 0 if len(temp) == 0 else (float(sum(temp)) / len(temp))  \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "class TextRNN(object):\n",
    "    def __init__(self, maxlen, max_features, embedding_dims,\n",
    "                 class_num=2,\n",
    "                 last_activation='sigmoid'):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "\n",
    "    def get_model(self):\n",
    "        input = Input((self.maxlen,))\n",
    "\n",
    "        embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)(input)\n",
    "        x = LSTM(128)(embedding)  # LSTM or GRU\n",
    "\n",
    "        output = Dense(self.class_num, activation=self.last_activation)(x)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 341,906\n",
      "Trainable params: 341,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_features = 5000\n",
    "maxlen = 128\n",
    "batch_size = 64\n",
    "embedding_dims = 50\n",
    "epochs = 100\n",
    "\n",
    "data = pd.read_csv('sentiment_data_v1.csv').dropna().reset_index(drop=True)\n",
    "data[\"text\"] = data[\"text\"].astype('string')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data[\"text\"], data[\"polarity\"],test_size=0.15)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data[\"text\"])\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(np.asarray(y_train).reshape(-1,1))\n",
    "y_test= encoder.fit_transform(np.asarray(y_test).reshape(-1,1))\n",
    "\n",
    "model = TextRNN(maxlen, max_features, embedding_dims).get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\nemo\\Anaconda3\\envs\\hate_speech_topic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 8493 samples, validate on 1499 samples\n",
      "Epoch 1/10\n",
      "8493/8493 [==============================] - 19s 2ms/step - loss: 0.3079 - acc: 0.8554 - val_loss: 0.1062 - val_acc: 0.9590\n",
      "Epoch 2/10\n",
      "8493/8493 [==============================] - 20s 2ms/step - loss: 0.0352 - acc: 0.9900 - val_loss: 0.0808 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "8493/8493 [==============================] - 20s 2ms/step - loss: 0.0172 - acc: 0.9962 - val_loss: 0.0815 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      "8493/8493 [==============================] - 21s 3ms/step - loss: 0.1788 - acc: 0.9708 - val_loss: 0.0814 - val_acc: 0.9797\n",
      "Epoch 5/10\n",
      "8493/8493 [==============================] - 24s 3ms/step - loss: 0.0232 - acc: 0.9962 - val_loss: 0.0865 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      "8493/8493 [==============================] - 27s 3ms/step - loss: 0.0112 - acc: 0.9982 - val_loss: 0.0763 - val_acc: 0.9820\n",
      "Epoch 7/10\n",
      "8493/8493 [==============================] - 26s 3ms/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0833 - val_acc: 0.9787\n",
      "Epoch 8/10\n",
      "8493/8493 [==============================] - 27s 3ms/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0805 - val_acc: 0.9820\n",
      "Epoch 9/10\n",
      "8493/8493 [==============================] - 29s 3ms/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0933 - val_acc: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119e064a508>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3, mode='max')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('sentiment_tokenizer_v1.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sentiment_model_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 그는 “ 문 정부의 코로나 대응을 폭주라고 이야기하면 어떻게 하자는 것이냐 ” 며 “ 야당이 생각하는 코로나19 대처는 지금보다 더 물렁물렁하게 , 느슨하게 하겠다는 이야기 아니냐 ” 고 비판했다 ']\n"
     ]
    }
   ],
   "source": [
    "input_sentences = [data[data['polarity']==1].reset_index(drop=True).text[1070]]\n",
    "print(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 그는 “ 문 정부의 코로나 대응을 폭주라고 이야기하면 어떻게 하자는 것이냐 ” 며 “ 야당이 생각하는 코로나19 대처는 지금보다 더 물렁물렁하게 , 느슨하게 하겠다는 이야기 아니냐 ” 고 비판했다  1 [9.3366508e-04 9.9906987e-01]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "import pickle \n",
    "\n",
    "with open('sentiment_tokenizer_v1.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "model = load_model('sentiment_model_v1.h5')\n",
    "predict = model.predict(sequence.pad_sequences(tokenizer.texts_to_sequences(input_sentences), maxlen=128))\n",
    "for i, pred in enumerate(predict):\n",
    "    print(input_sentences[i], pred.argmax(), pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hate_speech_topic]",
   "language": "python",
   "name": "conda-env-hate_speech_topic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
